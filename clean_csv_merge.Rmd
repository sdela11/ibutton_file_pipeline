---
title: "clean_csv_merge"
author: "Sara DeLaurentis"
date: "4/18/2022"
output: html_document
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/sbaue/coding/R_TEMPRY/Itasca_project_19-21")


library(tidyverse)
library(glue)
library(stringr)
library(lubridate)

```


## THIS IS THE CODE YOU'VE BEEN LOOKING FOR !!! ##
## VERY COOOlll lists ##

1. Make dataframe out of filenames in the desired folder or selection.
2. Turn each column into a list element with 5 named parts.
3. lapply function to the list of csv files with attached metadata.
    A. create df.
    B. create metadata columns in each.
    C. unify all date formats to POSIXct, format = YYYY-mm-dd HH:MM:SS
4. rowbind all of the dataframes together!!!
5. create .csv file.

Start by creating a dataframe based on the list of files.


```{r make.filelist, include = TRUE}

#create list of .csv files
m <- list.files("C:/Users/sbaue/coding/R_TEMPRY/Itasca_project_19-21/iButtons", pattern = "*.csv")
m

file_df <- data.frame(paths = m, name = str_replace(m, ".csv", ""), full_paths = list.files("C:/Users/sbaue/coding/R_TEMPRY/Itasca_project_19-21/iButtons", pattern = "*.csv", full.names = TRUE))

file_df

meta <- file_df$name %>%   #take the name column 
   str_split_fixed("_", n=5) %>% #split the strings, with _ as separator.
   as.data.frame() #COERCE
  colnames(meta) <- c("site", "rep", "position", "buttonID", "season") #
  #meta$CLEAN = NULL 
  
  
data.list.df <- cbind(file_df, meta)
  #  temp_df <- temp_df[, c(6,1,2,3,4,5,7,8)] # column re-ordering if necessary
#data.list.df <- data.list.df[order(data.list.df$site, data.list.df$rep, data.list.df$position, data.list.df$season), ] #for checking stuff

data.list.df <- data.list.df[order(data.list.df$name),]

view(data.list.df)

```


#What this does:

#1. Takes the dataframe we created from the names of the selected files, turns each ROW into ONE list element with "site", "rep", etc. as named elements contained inside.

#2. Uses lapply to read in the .csv files and attaches metadata.


```{r mega merge, include = TRUE}

files.meta.list <- list()                   # Create empty list

for(i in 1:nrow(data.list.df)) {   #for(each variable in the sequence "1 through the number of rows in data.list.df"):
                          
  files.meta.list[[i]] <- data.list.df[i , ]  #create an element in files.meta.list from each row found in data.list.df
}
#print(files.meta.list)

#Step 2: 

csv_LIST <- lapply(seq_along(files.meta.list), function(i){   

  df <- read.csv(files.meta.list[[i]]$full_paths, header=TRUE, sep = ",") #create "df" by reading the .csv given by full_paths.
  df$site <- files.meta.list[[i]]$site    #next few rows are the addition of metadata columns based on the named element in the list. 
  df$rep <- files.meta.list[[i]]$rep
  df$position <- files.meta.list[[i]]$position
  df$buttonID <- files.meta.list[[i]]$buttonID
  df$season <- files.meta.list[[i]]$season
  #print(df[1, "date.time"])
  df$date.time <- mdy_hms(df$date.time, tz = "America/Chicago", truncated = 3) #Get R to recognize your current date format
  df$date.time <- as.POSIXct((round(df$date.time, "mins")), tz = "America/Chicago") #Round off the seconds (turns into POSIXlt), re-convert to POSIXct.
 # print(df[1, "date.time"]) # for checks
 # print(df[4, "date.time"]) #for checks
  df #VERY IMPORTANT. I don't know why, but without this call for the whole dataframe, you get left with just the last column you created.
  })

finalTable <- do.call(rbind, csv_LIST) ##JOIN TOGETHER

class(finalTable$date.time)
str(finalTable)
head(finalTable)
view(finalTable)

#finalTable[(grep("12-28", finalTable$date.time)),] %>% filter(season == "2021")
#view(OlsonNames())
#output problem table if needed.
problems <- finalTable %>% filter(is.na(date.time))
view(problems)
#view(problems[problems$buttonID == "i45",])
#view(finalTable[finalTable$buttonID == "i101" & finalTable$season == "2021",])



#write.csv(finalTable, "ALL.csv")     ##Write the monster .csv

my.data = read.csv("ALL.csv")
view(my.data)

```
